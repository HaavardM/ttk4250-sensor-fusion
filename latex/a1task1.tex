\subsection{IMM-PDAF}
\subsubsection{IMM}
The behaviour of the targets we want to model might change over time, and any single (reasonably simple) model might not cover all situations. A better approach might be to combine multiple simple models with each model describing a subset of the system's behaviour. In our case we want to model a boat that is either moving straight forward or turning. We can then use an \textit{interactive multiple models} (IMM) approach to combine a CT (Constant Turn) and a CV (Constant Velocity) model. The IMM will weigh the different models based on how well they describe the current state (using the likelihood of the model being the correct one).

\subsubsection{PDAF}
No sensor is perfect and radars are no exception. The radar outputs a lot of measurements which may or may not originate from our target. To solve this we use a \texttt{probability data association filter} to associate measurements with our target and weigh them according to their likelihood of originating from our target.

We can combine the IMM and PDAF to develop the \texttt{interactive multiple models probability data association filter} to track a moving boat using radar detections.

\subsubsection{Implementation}
A normal IMM filter was developed according to chapter 6 in \cite{edmund} and was initialized with a CT and a CV EKF model. Most of the IMM-PDAF implementation is equal to the PDAF implementation described in chapter 7 in \cite{edmund} using the IMM as the model. There are however one difference that we should emphasize.

When updating the IMM conditional on each possible measurement association we get a new mixture model from the IMM with $M$ components. The total mixture model for the IMM-PDAF after one iteration (assuming single gaussian input) is therefore a mixture model with $(N+1)M$Â components where $N$ is the number of gated measurements and $M$ is the number of models. This will again continue to grow for each timestep as new measurements will create additional components.

We therefore want to reduce the number of components by conditioning the association probabilities on the mode probabilities. Further we reduce the mixture for each mode to a single gaussian component using equations (6.18) and (6.20) from \cite{edmund}. The association probabilities conditioned on the mode are used as weights.




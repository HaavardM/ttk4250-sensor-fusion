\section{}
\subsection{Introduction}
\subsubsection{The SLAM Problem}
In any autonomous manouvering situation, be it for a robot, a wheeled vehicle, a flying drone or anything in between, the need for localization is vital.
Localization alone however is only really meaningful in relation to the environment the robot is in.
The SLAM – simultaneous localization and mapping – problem arises then, as the need to simultaneously locate the robot as well as map out its environment.

This problem is naturally non-trivial and has consequently been the topic of extensive research in the last few decades.
There are multiple difficult aspects of the problem that must be solved for a SLAM-system to be successful.
Odometry, i.e. measuring the movement of the robot, map feature/landmark detection, data association as well as estimation and tracking are among the central parts of the SLAM problem that must all be solved.
One of the earliest SLAM solvers, which is the one we will be considering in this assignment is EKF-SLAM, in which an extended Kalman filter fuses together odometric measurements with associated landmark measurements to provide a continuously improved map of the environment and the vehicle position within it.

\subsubsection{EKF-SLAM in Intuitive Terms}
In our problem formulation, we are considering the odometry of the vehicle as given at each timestep, e.g. from an IMU or wheel encoders.
Using this information, typically in the form of velocity estimates or displacement increments, the vehicle can perform dead reckoning to give an indication of where the it has moved over time.
Such a scheme quickly breaks down however, as the inevitably imprecise odometric measurements, when integrated, will give rise to an ever accumulating deviation from the true position of the vehicle. In Kalman filter terms, this corresponds to performing consecutive prediction steps for all time. In order to remove deviations, the natural extension to this scheme is then to include an update step, where the pose, i.e. the position and orientation of the vehicle is updated with information gathered from observing the environment. In that sense, EKF-SLAM is similar to the ESKF, with landmark measurements replacing GNSS for global position updating.

\subsection{Our EKF-SLAM Implementation}
The problem we are considering in this assignment is two-dimensional SLAM, meaning the vehicle is modeled with three degrees of freedom, $x$, $y$ position and orientation $\psi$. In contrast, the ESFK in \ref{sec:a2} was able to represent 6 degrees of freedom. The other major difference is that the state vector in EKF-SLAM contains all the discovered landmarks. We call this state vector the joint pose-landmark vector $\eta_k = \begin{bmatrix} \mathbf{x}_k & \mathbf{m} \end{bmatrix}^{\top}$ as it contains both the pose and all landmarks detected up to the current timestep. In the predict step of the EKF, the pose is compounded (i.e. added in a geometrically meaningful way) with the current odometric vector $\mathbf{u}_k$, in addition to updating the covariance matrix. The update step however is where the action happens. During this step, the EKF does three things. Firstly, it associates new measurements with existing landmarks using Joint Compatibility Branch and Bound, or JCBB for short. Secondly, it calculates an innovation term from the associations that it does an Kalman update step with. Lastly, it augments the state vector with new landmarks – one for each unassociated measurement.

\subsubsection{Joint Compatibility Branch and Bound}
As mentioned, our implementation uses the JCBB algorithm for associating measurements with landmarks. The important feature of this algorithm is that is finds the best joint compatibility in addition to individual compatibility. For SLAM, joint compatibility is absolutely necessary as a set of individually compatible measurements can still be jointly incompatible and updating the Kalman filter with such an association can cause it to diverge.\cite{jcbb}



\input{a3task2}
\input{a3task3}
\input{a3discussion}

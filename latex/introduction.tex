\subsection{Abstract}
Sensor Fusion is an important aspect of modern robotics. Any single sensor is never perfect, and the need for fusing together multiple sensors is crucial to allow machines to percieve our world. In this report we will implement three different solutions to three different problems using sensor fusion, using a bayesian framework. The implementations performance and consistency will be discusses using common metrics such as NEES and NIS, and we will compare the results from simulations with the results from real world data. 
\subsection{Introduction}
The course \texttt{TTK4250 Sensor Fusion} introduce several methods for target tracking, navigation and mapping using a variety of sensors. During the course we have developed a radar tracker for boats using an \texttt{interactive multiple models probability data association filter} and tested it on real world data from the \texttt{Joyride} dataset. We have also created an \texttt{error state kalman filter} tracking the 6 degrees of freedom of an airplane using inertial navigation and GNSS. Lastly we have done \texttt{simultanious localization and mapping} using odometry and LIDAR by implementing an EKF-SLAM approach. In this report we will summarize our approach and findings for all three methods. 